Function profiling
==================
  Message: /home/guus/anaconda3/envs/pcntk_dev/lib/python3.12/site-packages/pymc/pytensorf.py:1039
  Time in 1000 calls to Function.__call__: 3.243908e-01s
  Time in Function.vm.__call__: 0.22749889914121013s (70.131%)
  Time in thunks: 0.1995844841003418s (61.526%)
  Total compilation time: 8.335058e-01s
    Number of Apply nodes: 31
    PyTensor rewrite time: 7.739202e-01s
       PyTensor validate time: 1.021461e-02s
    PyTensor Linker time (includes C, CUDA code generation/compiling): 0.055231068006833084s
       C-cache preloading 1.112853e-02s
       Import time 0.000000e+00s
       Node make_thunk time 4.296037e-02s
           Node ExpandDims{axis=0}(intercept_sigma) time 3.702187e-03s
           Node ExpandDims{axes=[0, 1]}(mu_intercept_mu) time 2.847014e-03s
           Node ExpandDims{axis=0}(All{axes=None}.0) time 2.783239e-03s
           Node ExpandDims{axes=[0, 1]}(Composite{...}.0) time 2.487330e-03s
           Node ExpandDims{axes=[0, 1]}(mu_slope_mu) time 2.246213e-03s

Time in all call to pytensor.grad() 7.197635e+00s
Time since pytensor import 1044.882s
Class
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Class name>
  38.9%    38.9%       0.078s       3.88e-05s     Py    2000       2   pytensor.tensor.subtensor.AdvancedSubtensor
  26.9%    65.8%       0.054s       4.13e-06s     C    13000      13   pytensor.tensor.elemwise.Elemwise
  17.2%    83.0%       0.034s       4.91e-06s     C     7000       7   pytensor.tensor.elemwise.DimShuffle
  15.8%    98.8%       0.032s       3.95e-06s     C     8000       8   pytensor.tensor.math.Sum
   1.2%   100.0%       0.002s       2.32e-06s     C     1000       1   pytensor.tensor.math.All
   ... (remaining 0 Classes account for   0.00%(0.00s) of the runtime)

Ops
---
<% time> <sum %> <apply time> <time per call> <type> <#call> <#apply> <Op name>
  38.9%    38.9%       0.078s       3.88e-05s     Py    2000        2   AdvancedSubtensor
  13.7%    52.6%       0.027s       2.73e-05s     C     1000        1   Composite{...}
  11.2%    63.8%       0.022s       1.12e-05s     C     2000        2   Sum{axis=1}
   4.9%    68.6%       0.010s       4.85e-06s     C     2000        2   ExpandDims{axis=0}
   4.6%    73.3%       0.009s       1.54e-06s     C     6000        6   Sum{axes=None}
   4.6%    77.9%       0.009s       9.14e-06s     C     1000        1   ExpandDims{axis=0}
   4.2%    82.0%       0.008s       4.16e-06s     C     2000        2   ExpandDims{axes=[0, 1]}
   3.8%    85.8%       0.008s       7.57e-06s     C     1000        1   Mul
   3.6%    89.4%       0.007s       3.59e-06s     C     2000        2   ExpandDims{axes=[0, 1]}
   2.6%    92.0%       0.005s       5.10e-06s     C     1000        1   Mul
   1.6%    93.6%       0.003s       1.59e-06s     C     2000        2   Composite{(i2 + (i0 * i1))}
   1.2%    94.7%       0.002s       2.32e-06s     C     1000        1   All{axes=None}
   0.9%    95.7%       0.002s       1.89e-06s     C     1000        1   Composite{((-0.5 * sqr((0.1 * i0))) - 3.221523658174155)}
   0.9%    96.6%       0.002s       9.09e-07s     C     2000        2   Composite{((-0.5 * sqr(i0)) - 0.9189385332046727)}
   0.8%    97.4%       0.002s       1.59e-06s     C     1000        1   Composite{...}
   0.8%    98.1%       0.002s       1.50e-06s     C     1000        1   Composite{...}
   0.7%    98.9%       0.001s       1.47e-06s     C     1000        1   Composite{(i3 + i4 + i5 + i6 + (i2 * sqr((i0 * i12))) + i7 + i8 + i9 + i10 + (i2 * sqr((i0 * i1))) + i11)}
   0.7%    99.6%       0.001s       1.42e-06s     C     1000        1   Switch
   0.4%   100.0%       0.001s       8.35e-07s     C     1000        1   Composite{((-0.5 * sqr((0.2 * i0))) - 2.5283764757095555)}
   ... (remaining 0 Ops account for   0.00%(0.00s) of the runtime)

Apply
------
<% time> <sum %> <apply time> <time per call> <#call> <id> <Apply name>
  25.1%    25.1%       0.050s       5.02e-05s   1000     9   AdvancedSubtensor(Composite{(i2 + (i0 * i1))}.0, sex_data, site_data)
  13.8%    38.9%       0.027s       2.75e-05s   1000     4   AdvancedSubtensor(Composite{(i2 + (i0 * i1))}.0, sex_data, site_data)
  13.7%    52.6%       0.027s       2.73e-05s   1000    16   Composite{...}(Sum{axis=1}.0, ExpandDims{axis=0}.0, y, Sum{axis=1}.0, AdvancedSubtensor.0)
   5.6%    58.2%       0.011s       1.12e-05s   1000    11   Sum{axis=1}(Mul.0)
   5.6%    63.8%       0.011s       1.11e-05s   1000    15   Sum{axis=1}(Mul.0)
   4.6%    68.4%       0.009s       9.14e-06s   1000    13   ExpandDims{axis=0}(slope_sigma)
   3.8%    72.1%       0.008s       7.57e-06s   1000    14   Mul(ExpandDims{axis=0}.0, X)
   2.7%    74.9%       0.005s       5.48e-06s   1000     2   ExpandDims{axes=[0, 1]}(Composite{...}.0)
   2.7%    77.6%       0.005s       5.34e-06s   1000    18   ExpandDims{axis=0}(All{axes=None}.0)
   2.6%    80.1%       0.005s       5.10e-06s   1000    10   Mul(AdvancedSubtensor.0, X)
   2.2%    82.3%       0.004s       4.36e-06s   1000    12   ExpandDims{axis=0}(intercept_sigma)
   1.9%    84.2%       0.004s       3.79e-06s   1000     7   ExpandDims{axes=[0, 1]}(Composite{...}.0)
   1.7%    85.9%       0.003s       3.40e-06s   1000     5   ExpandDims{axes=[0, 1]}(mu_slope_mu)
   1.4%    87.3%       0.003s       2.84e-06s   1000     0   ExpandDims{axes=[0, 1]}(mu_intercept_mu)
   1.3%    88.6%       0.003s       2.50e-06s   1000    20   Sum{axes=None}(sigma > 0)
   1.2%    89.7%       0.002s       2.32e-06s   1000    17   All{axes=None}(Composite{...}.0)
   1.0%    90.7%       0.002s       1.93e-06s   1000    29   Sum{axes=None}(sigma > 0)
   0.9%    91.7%       0.002s       1.89e-06s   1000    28   Composite{((-0.5 * sqr((0.1 * i0))) - 3.221523658174155)}(mu_slope_mu)
   0.9%    92.6%       0.002s       1.82e-06s   1000    26   Sum{axes=None}(sigma > 0)
   0.9%    93.4%       0.002s       1.72e-06s   1000     8   Composite{(i2 + (i0 * i1))}(offset_slope_mu, ExpandDims{axes=[0, 1]}.0, ExpandDims{axes=[0, 1]}.0)
   ... (remaining 11 Apply instances account for 6.57%%(0.01s) of the runtime)

Here are tips to potentially make your code run faster
                 (if you think of new ones, suggest them on the mailing list).
                 Test them first, as they are not guaranteed to always provide a speedup.
  - Try the PyTensor flag floatX=float32
  - Try installing amdlibm and set the PyTensor flag lib__amdlibm=True. This speeds up only some Elemwise operation.
